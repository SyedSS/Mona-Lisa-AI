{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal is to answer the question: can a machine detect a person's gender based on their tweet?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "1. Get twitter data\n",
    "2. Clean\n",
    "3. Analyze and visualize\n",
    "4. Build model\n",
    "5. Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tweepy as tw\n",
    "import seaborn as sns\n",
    "import json\n",
    "import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk import PorterStemmer\n",
    "import textblob\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweepy.api.API"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to twitter API\n",
    "path_auth = '/Users/allenj/Documents/Keys/auth_twitter.json'\n",
    "auth = json.loads(open(path_auth).read())\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "my_consumer_key = auth['my_consumer_key']\n",
    "my_consumer_secret = auth['my_consumer_secret']\n",
    "my_access_token = auth['your_access_token']\n",
    "my_access_token_secret = auth['my_access_token_secret']\n",
    "\n",
    "auth = tw.OAuthHandler(my_consumer_key, my_consumer_secret)\n",
    "auth.set_access_token(my_access_token, my_access_token_secret)\n",
    "api = tw.API(auth)\n",
    "\n",
    "type(api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get Twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>followers_millions</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>Politician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>justinbieber</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>Musician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>katyperry</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>1</td>\n",
       "      <td>108.0</td>\n",
       "      <td>Musician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>rihanna</td>\n",
       "      <td>Rihanna</td>\n",
       "      <td>1</td>\n",
       "      <td>96.0</td>\n",
       "      <td>Musician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>taylorswift13</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>1</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Musician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Cristiano</td>\n",
       "      <td>Cristiano Ronaldo</td>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>Athlete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Politician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>ladygaga</td>\n",
       "      <td>Lady Gaga</td>\n",
       "      <td>1</td>\n",
       "      <td>81.0</td>\n",
       "      <td>Musician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>TheEllenShow</td>\n",
       "      <td>Ellen DeGeneres</td>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Comedian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>ArianaGrande</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>1</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Musician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>KimKardashian</td>\n",
       "      <td>Kim Kardashian</td>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Celebrity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>jtimberlake</td>\n",
       "      <td>Justin Timberlake</td>\n",
       "      <td>0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Musician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>selenagomez</td>\n",
       "      <td>Selena Gomez</td>\n",
       "      <td>1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Musician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>narendramodi</td>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Politician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>britneyspears</td>\n",
       "      <td>Britney Spears</td>\n",
       "      <td>1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Musician</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               user               name  gender  followers_millions    activity\n",
       "0       BarackObama       Barack Obama       0               118.0  Politician\n",
       "1      justinbieber      Justin Bieber       0               111.0    Musician\n",
       "2         katyperry         Katy Perry       1               108.0    Musician\n",
       "3           rihanna            Rihanna       1                96.0    Musician\n",
       "4     taylorswift13       Taylor Swift       1                86.0    Musician\n",
       "5         Cristiano  Cristiano Ronaldo       0                84.0     Athlete\n",
       "6   realDonaldTrump       Donald Trump       0                82.0  Politician\n",
       "7          ladygaga          Lady Gaga       1                81.0    Musician\n",
       "8      TheEllenShow    Ellen DeGeneres       1                80.0    Comedian\n",
       "9      ArianaGrande      Ariana Grande       1                74.0    Musician\n",
       "10    KimKardashian     Kim Kardashian       1                65.0   Celebrity\n",
       "11      jtimberlake  Justin Timberlake       0                64.0    Musician\n",
       "12      selenagomez       Selena Gomez       1                61.0    Musician\n",
       "13     narendramodi      Narendra Modi       0                57.0  Politician\n",
       "14    britneyspears     Britney Spears       1                56.0    Musician"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload list of desired users\n",
    "# Gender 0 = male, 1 = female\n",
    "users = pd.read_csv('../Data/twitter-users.csv')\n",
    "users.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    47\n",
       "0    36\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>We’ve seen the power that our voices have when...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>On National Gun Violence Awareness Day, we #We...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>Third, every city in this country should be a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>Second, every mayor should review their use of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>First, there are specific evidence-based refor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>developingjen</td>\n",
       "      <td>Fascinating. // This is Your Brain on LSD http...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>developingjen</td>\n",
       "      <td>THIS! // Stacy Brown-Philpot tapped as new Tas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>developingjen</td>\n",
       "      <td>Sean Parker, a Facebook and Napster Pioneer, t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>developingjen</td>\n",
       "      <td>@harper Christian Loffler, Veiled Grey. Massiv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>developingjen</td>\n",
       "      <td>@harper Peter Broderick: With Notes In My Ears...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12919 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              user                                               text  gender\n",
       "0      BarackObama  We’ve seen the power that our voices have when...       0\n",
       "1      BarackObama  On National Gun Violence Awareness Day, we #We...       0\n",
       "2      BarackObama  Third, every city in this country should be a ...       0\n",
       "3      BarackObama  Second, every mayor should review their use of...       0\n",
       "4      BarackObama  First, there are specific evidence-based refor...       0\n",
       "..             ...                                                ...     ...\n",
       "190  developingjen  Fascinating. // This is Your Brain on LSD http...       1\n",
       "191  developingjen  THIS! // Stacy Brown-Philpot tapped as new Tas...       1\n",
       "192  developingjen  Sean Parker, a Facebook and Napster Pioneer, t...       1\n",
       "193  developingjen  @harper Christian Loffler, Veiled Grey. Massiv...       1\n",
       "194  developingjen  @harper Peter Broderick: With Notes In My Ears...       1\n",
       "\n",
       "[12919 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get collection of tweets from these usernames and store it into a new dataframe\n",
    "list = []\n",
    "\n",
    "for index, row in users.iterrows():\n",
    "    tweets = api.user_timeline(screen_name=row['user'], count=200, include_rts=False)\n",
    "    users_text = [[tweet.user.screen_name, tweet.text, row['gender']] for tweet in tweets]\n",
    "    tweet_text = pd.DataFrame(data=users_text, \n",
    "                        columns=[\"user\", \"text\", \"gender\"])\n",
    "    list.append(tweet_text)\n",
    "\n",
    "# Merge the list    \n",
    "tweets = pd.concat(list) \n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user            gender\n",
       "AdamMGrant      0         200\n",
       "Adele           1         194\n",
       "AnushkaSharma   1         156\n",
       "ArianaGrande    1         107\n",
       "AvrilLavigne    1         135\n",
       "                         ... \n",
       "staceyannchin   1         168\n",
       "susanmcp1       1          60\n",
       "taylorswift13   1         189\n",
       "unhealthytruth  1         151\n",
       "wizkhalifa      0          97\n",
       "Length: 83, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of datapoints per person\n",
    "tweets.groupby([\"user\", \"gender\"]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # reduce multiple spaces and newlines to only one\n",
    "    text = re.sub(r'(\\s\\s+|\\n\\n+)', r'\\1', text)\n",
    "    # remove double quotes\n",
    "    text = re.sub(r'\"', '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>We’ve seen the power that our voices have when...</td>\n",
       "      <td>0</td>\n",
       "      <td>We’ve seen the power that our voices have when...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>On National Gun Violence Awareness Day, we #We...</td>\n",
       "      <td>0</td>\n",
       "      <td>On National Gun Violence Awareness Day, we #We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>Third, every city in this country should be a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Third, every city in this country should be a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>Second, every mayor should review their use of...</td>\n",
       "      <td>0</td>\n",
       "      <td>Second, every mayor should review their use of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>First, there are specific evidence-based refor...</td>\n",
       "      <td>0</td>\n",
       "      <td>First, there are specific evidence-based refor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>developingjen</td>\n",
       "      <td>Fascinating. // This is Your Brain on LSD http...</td>\n",
       "      <td>1</td>\n",
       "      <td>Fascinating. // This is Your Brain on LSD http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>developingjen</td>\n",
       "      <td>THIS! // Stacy Brown-Philpot tapped as new Tas...</td>\n",
       "      <td>1</td>\n",
       "      <td>THIS! // Stacy Brown-Philpot tapped as new Tas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>developingjen</td>\n",
       "      <td>Sean Parker, a Facebook and Napster Pioneer, t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Sean Parker, a Facebook and Napster Pioneer, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>developingjen</td>\n",
       "      <td>@harper Christian Loffler, Veiled Grey. Massiv...</td>\n",
       "      <td>1</td>\n",
       "      <td>@harper Christian Loffler, Veiled Grey. Massiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>developingjen</td>\n",
       "      <td>@harper Peter Broderick: With Notes In My Ears...</td>\n",
       "      <td>1</td>\n",
       "      <td>@harper Peter Broderick: With Notes In My Ears...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12919 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              user                                               text  gender                                         clean_text\n",
       "0      BarackObama  We’ve seen the power that our voices have when...       0  We’ve seen the power that our voices have when...\n",
       "1      BarackObama  On National Gun Violence Awareness Day, we #We...       0  On National Gun Violence Awareness Day, we #We...\n",
       "2      BarackObama  Third, every city in this country should be a ...       0  Third, every city in this country should be a ...\n",
       "3      BarackObama  Second, every mayor should review their use of...       0  Second, every mayor should review their use of...\n",
       "4      BarackObama  First, there are specific evidence-based refor...       0  First, there are specific evidence-based refor...\n",
       "..             ...                                                ...     ...                                                ...\n",
       "190  developingjen  Fascinating. // This is Your Brain on LSD http...       1  Fascinating. // This is Your Brain on LSD http...\n",
       "191  developingjen  THIS! // Stacy Brown-Philpot tapped as new Tas...       1  THIS! // Stacy Brown-Philpot tapped as new Tas...\n",
       "192  developingjen  Sean Parker, a Facebook and Napster Pioneer, t...       1  Sean Parker, a Facebook and Napster Pioneer, t...\n",
       "193  developingjen  @harper Christian Loffler, Veiled Grey. Massiv...       1  @harper Christian Loffler, Veiled Grey. Massiv...\n",
       "194  developingjen  @harper Peter Broderick: With Notes In My Ears...       1  @harper Peter Broderick: With Notes In My Ears...\n",
       "\n",
       "[12919 rows x 4 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['clean_text'] = tweets['text'].apply(clean_text)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "\n",
    "def convert_text(text):\n",
    "    sent = nlp(text)\n",
    "    ents = {x.text: x for x in sent.ents}\n",
    "    tokens = []\n",
    "    for w in sent:\n",
    "        if w.is_stop or w.is_punct:\n",
    "            continue\n",
    "        if w.text in ents:\n",
    "            tokens.append(w.text)\n",
    "        else:\n",
    "            tokens.append(w.lemma_.lower())\n",
    "    text = ' '.join(tokens)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>We’ve seen the power that our voices have when...</td>\n",
       "      <td>0</td>\n",
       "      <td>see power voice speak injustice––but know toll...</td>\n",
       "      <td>see power voice speak injustice––but know toll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>On National Gun Violence Awareness Day, we #We...</td>\n",
       "      <td>0</td>\n",
       "      <td>national gun violence awareness day WearOrange...</td>\n",
       "      <td>national gun violence awareness day WearOrange...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>Third, every city in this country should be a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>city country @MBK_Alliance community 250 city ...</td>\n",
       "      <td>city country @MBK_Alliance community 250 city ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>Second, every mayor should review their use of...</td>\n",
       "      <td>0</td>\n",
       "      <td>Second mayor review use force policy member co...</td>\n",
       "      <td>Second mayor review use force policy member co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>First, there are specific evidence-based refor...</td>\n",
       "      <td>0</td>\n",
       "      <td>specific evidence base reform build trust save...</td>\n",
       "      <td>specific evidence base reform build trust save...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>developingjen</td>\n",
       "      <td>Fascinating. // This is Your Brain on LSD http...</td>\n",
       "      <td>1</td>\n",
       "      <td>fascinating brain lsd https://t.co/htlhpxjiqi ...</td>\n",
       "      <td>fascinating brain lsd https://t.co/htlhpxjiqi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>developingjen</td>\n",
       "      <td>THIS! // Stacy Brown-Philpot tapped as new Tas...</td>\n",
       "      <td>1</td>\n",
       "      <td>stacy brown philpot tap new TaskRabbit ceo htt...</td>\n",
       "      <td>stacy brown philpot tap new TaskRabbit ceo htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>developingjen</td>\n",
       "      <td>Sean Parker, a Facebook and Napster Pioneer, t...</td>\n",
       "      <td>1</td>\n",
       "      <td>sean parker Facebook napster pioneer start can...</td>\n",
       "      <td>sean parker Facebook napster pioneer start can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>developingjen</td>\n",
       "      <td>@harper Christian Loffler, Veiled Grey. Massiv...</td>\n",
       "      <td>1</td>\n",
       "      <td>@harper christian loffler veiled grey massive ...</td>\n",
       "      <td>@harper christian loffler veiled grey massive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>developingjen</td>\n",
       "      <td>@harper Peter Broderick: With Notes In My Ears...</td>\n",
       "      <td>1</td>\n",
       "      <td>@harper peter broderick note ear alright   sia...</td>\n",
       "      <td>@harper peter broderick note ear alright   sia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12919 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              user                                               text  gender                                         clean_text                                        clean_text2\n",
       "0      BarackObama  We’ve seen the power that our voices have when...       0  see power voice speak injustice––but know toll...  see power voice speak injustice––but know toll...\n",
       "1      BarackObama  On National Gun Violence Awareness Day, we #We...       0  national gun violence awareness day WearOrange...  national gun violence awareness day WearOrange...\n",
       "2      BarackObama  Third, every city in this country should be a ...       0  city country @MBK_Alliance community 250 city ...  city country @MBK_Alliance community 250 city ...\n",
       "3      BarackObama  Second, every mayor should review their use of...       0  Second mayor review use force policy member co...  Second mayor review use force policy member co...\n",
       "4      BarackObama  First, there are specific evidence-based refor...       0  specific evidence base reform build trust save...  specific evidence base reform build trust save...\n",
       "..             ...                                                ...     ...                                                ...                                                ...\n",
       "190  developingjen  Fascinating. // This is Your Brain on LSD http...       1  fascinating brain lsd https://t.co/htlhpxjiqi ...  fascinating brain lsd https://t.co/htlhpxjiqi ...\n",
       "191  developingjen  THIS! // Stacy Brown-Philpot tapped as new Tas...       1  stacy brown philpot tap new TaskRabbit ceo htt...  stacy brown philpot tap new TaskRabbit ceo htt...\n",
       "192  developingjen  Sean Parker, a Facebook and Napster Pioneer, t...       1  sean parker Facebook napster pioneer start can...  sean parker Facebook napster pioneer start can...\n",
       "193  developingjen  @harper Christian Loffler, Veiled Grey. Massiv...       1  @harper christian loffler veiled grey massive ...  @harper christian loffler veiled grey massive ...\n",
       "194  developingjen  @harper Peter Broderick: With Notes In My Ears...       1  @harper peter broderick note ear alright   sia...  @harper peter broderick note ear alright   sia...\n",
       "\n",
       "[12919 rows x 5 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['clean_text'] = tweets['clean_text'].apply(convert_text)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['clean_text'] = tweets['text']\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text by removing things\n",
    "def remove_pattern(text,pattern):\n",
    "    \n",
    "    # re.findall() finds the pattern i.e @user and puts it in a list for further task\n",
    "    r = re.findall(pattern,text)\n",
    "    \n",
    "    # re.sub() removes @user from the sentences in the dataset\n",
    "    for i in r:\n",
    "        text = re.sub(i,\"\",text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "#Remove @ symbol, URL links, and \"&amp;\"\n",
    "tweets['clean_text'] = np.vectorize(remove_pattern)(tweets['text'], \"@[\\w]*\") #removes all @\n",
    "tweets['clean_text'] = np.vectorize(remove_pattern)(tweets['clean_text'], \"&amp;\")\n",
    "tweets['clean_text'] = np.vectorize(remove_pattern)(tweets['clean_text'], \"#[\\w]*\") #removes all hashtags\n",
    "tweets['clean_text'] = np.vectorize(remove_pattern)(tweets['clean_text'], \"https:\\/\\/.*[\\r\\n]*\")\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = pd.read_csv('../Data/twitter-test.csv')\n",
    "testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for the testing dataset\n",
    "# Clean text by removing things\n",
    "testset['clean_text'] = np.vectorize(remove_pattern)(testset['text'], \"@[\\w]*\") #removes all @\n",
    "testset['clean_text'] = np.vectorize(remove_pattern)(testset['clean_text'], \"https?:\\/\\/.*[\\r\\n]*\")\n",
    "testset['clean_text'] = np.vectorize(remove_pattern)(testset['clean_text'], \"&amp;\")\n",
    "testset['clean_text'] = np.vectorize(remove_pattern)(testset['clean_text'], \"#[\\w]*\") #removes all hashtags\n",
    "testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation, numbers, and special characters\n",
    "tweets['clean_text'] = tweets['clean_text'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for the testing dataset\n",
    "# Remove punctuation, numbers, and special characters\n",
    "testset['clean_text'] = testset['clean_text'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove short words less than 3\n",
    "tweets['clean_text'] = tweets['clean_text'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "tweets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for the testing dataset\n",
    "# Remove short words less than 2\n",
    "testset['clean_text'] = testset['clean_text'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "testset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new column to count length of clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count length of characters\n",
    "tweets['length'] = tweets['clean_text'].apply(len)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for the testing dataset\n",
    "# Count length\n",
    "testset['length'] = testset['clean_text'].apply(len)\n",
    "testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rows in training data that have less than desired text length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(tweets['length'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where length <= 30\n",
    "tweets = tweets[tweets.length > 30]\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(tweets['length'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize, stem, and stich back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # reduce multiple spaces and newlines to only one\n",
    "    text = re.sub(r'(\\s\\s+|\\n\\n+)', r'\\1', text)\n",
    "    # remove double quotes\n",
    "    text = re.sub(r'\"', '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['clean_text2'] = tweets['text'].apply(clean_text)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text(text):\n",
    "    sent = nlp(text)\n",
    "    ents = {x.text: x for x in sent.ents}\n",
    "    tokens = []\n",
    "    for w in sent:\n",
    "        if w.is_stop or w.is_punct:\n",
    "            continue\n",
    "        if w.text in ents:\n",
    "            tokens.append(w.text)\n",
    "        else:\n",
    "            tokens.append(w.lemma_.lower())\n",
    "    text = ' '.join(tokens)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['clean_text2'] = tweets['text'].apply(convert_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google 'pandas' .apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to capitalize all characters\n",
    "def capitalize(x):\n",
    "    return x.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'allen'\n",
    "capitalize(test)\n",
    "# do this for df column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda is a one use function that you don't need to define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tokenization\n",
    "# tokenized_tweet = tweets['clean_text'].apply(lambda x: x.split())\n",
    "# tokenized_tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Do the same for the testing dataset\n",
    "# # Tokenization\n",
    "# tokenized_testset = testset['clean_text'].apply(lambda x: x.split())\n",
    "# tokenized_testset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stemming\n",
    "# ps = PorterStemmer()\n",
    "# tokenized_tweet = tokenized_tweet.apply(lambda x: [ps.stem(i) for i in x])\n",
    "# tokenized_tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Do the same for the testing dataset\n",
    "# # Stemming\n",
    "# ps = PorterStemmer()\n",
    "# tokenized_testset = tokenized_testset.apply(lambda x: [ps.stem(i) for i in x])\n",
    "# tokenized_testset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stich tokens back together\n",
    "# for i in range(len(tokenized_tweet)):\n",
    "#     tokenized_tweet[i] = ' '.join(tokenized_tweet[i])\n",
    "          \n",
    "# testset['clean_text'] = tokenized_tweet\n",
    "# testset['clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stich tokens back together\n",
    "# for i in range(len(tokenized_tweet)):\n",
    "#     tokenized_tweet[i] = ' '.join(tokenized_tweet[i])\n",
    "          \n",
    "# testset['clean_text'] = tokenized_tweet\n",
    "# testset['clean_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Selectioin and Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag-of-Words features\n",
    "bow_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Bag-of-Words feature matrix\n",
    "bow = bow_vectorizer.fit_transform(tweets['clean_text'])\n",
    "df_bow = pd.DataFrame(bow.todense(), columns=bow_vectorizer.get_feature_names())\n",
    "df_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for test dataset\n",
    "# Bag-of-Words feature matrix\n",
    "bow = bow_vectorizer.transform(testset['clean_text'])\n",
    "df_bow_test = pd.DataFrame(bow.todense(), columns=bow_vectorizer.get_feature_names())\n",
    "df_bow_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Bag of Words to Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and validation set\n",
    "X = df_bow\n",
    "y = tweets['gender']\n",
    "\n",
    "# Use Bag-of-Words Features\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting on Logistic Regression model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first part of the list is predicting probabilities for gender:0 (male)\n",
    "# The second part of the list is predicting probabilities for gender:1 (female)\n",
    "prediction_bow = logreg.predict_proba(X_test_bow)\n",
    "prediction_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the F1 score\n",
    "# If prediction is greater than or equal to 0.3 than 1, else 0\n",
    "# Where 0 is for male tweets and 1 is for female tweets\n",
    "prediction_int = prediction_bow[:,1]>=0.5\n",
    "\n",
    "prediction_int = prediction_int.astype(np.int)\n",
    "prediction_int\n",
    "\n",
    "# Calculating f1 score\n",
    "log_bow = f1_score(y_test_bow, prediction_int)\n",
    "\n",
    "log_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with separate test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is a fit model\n",
    "logreg.intercept_, logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = df_bow_test\n",
    "pred = logreg.predict_proba(z)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = logreg.predict(z)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=pred)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = pd.DataFrame(data=pred2, columns=['predicted_gender'])\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.join(pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF features (Term Frequency-Inverse Document Frequency)\n",
    "tfidf=TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix=tfidf.fit_transform(tweets['clean_text'])\n",
    "df_tfidf = pd.DataFrame(tfidf_matrix.todense(), columns=tfidf.get_feature_names())\n",
    "df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for the test dataset\n",
    "# TF-IDF features (Term Frequency-Inverse Document Frequency)\n",
    "tfidf_matrix=tfidf.transform(testset['clean_text'])\n",
    "df_tfidf_test = pd.DataFrame(tfidf_matrix.todense(), columns=tfidf.get_feature_names())\n",
    "df_tfidf_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use TF-IDF to Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and validation set\n",
    "X = df_tfidf\n",
    "y = tweets['gender']\n",
    "\n",
    "# Use Bag-of-Words Features\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using TF-IDF Features\n",
    "logreg.fit(X_train_tfidf, y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_tfidf = logreg.predict_proba(X_test_tfidf)\n",
    "prediction_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the F1 score\n",
    "prediction_int = prediction_tfidf[:,1]>=0.5\n",
    "prediction_int = prediction_int.astype(np.int)\n",
    "prediction_int\n",
    "\n",
    "# calculating f1 score\n",
    "log_tfidf = f1_score(y_test_tfidf, prediction_int)\n",
    "log_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "dtc = DecisionTreeClassifier(criterion='entropy', random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Bag of Words as features\n",
    "dtc.fit(X_train_bow, y_train_bow)\n",
    "dtc_bow = dtc.predict_proba(X_test_bow)\n",
    "dtc_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if prediction is greater than or equal to 0.3 than 1 else 0\n",
    "# Where 0 is for positive sentiment tweets and 1 for negative sentiment tweets\n",
    "dtc_bow = dtc_bow[:,1]>=0.5\n",
    "\n",
    "# converting the results to integer type\n",
    "dtc_int_bow=dtc_bow.astype(np.int)\n",
    "\n",
    "# calculating f1 score\n",
    "dtc_score_bow=f1_score(y_test_bow, dtc_int_bow)\n",
    "\n",
    "dtc_score_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using TF-IDF\n",
    "dtc.fit(x_train_tfidf,y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_tfidf = dtc.predict_proba(X_test_tfidf)\n",
    "\n",
    "dtc_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if prediction is greater than or equal to 0.3 than 1 else 0\n",
    "# Where 0 is for positive sentiment tweets and 1 for negative sentiment tweets\n",
    "dtc_tfidf=dtc_tfidf[:,1]>=0.3\n",
    "\n",
    "# converting the results to integer type\n",
    "dtc_int_tfidf=dtc_tfidf.astype(np.int)\n",
    "\n",
    "# calculating f1 score\n",
    "dtc_score_tfidf=f1_score(y_test_tfidf,dtc_int_tfidf)\n",
    "\n",
    "dtc_score_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Comparison\n",
    "Algo=['LogisticRegression(Bag-of-Words)','DecisionTree(Bag-of-Words)','LogisticRegression(TF-IDF)','DecisionTree(TF-IDF)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = [log_bow,dct_score_bow,log_tfidf,dct_score_tfidf]\n",
    "\n",
    "compare=pd.DataFrame({'Model':Algo,'F1_Score':score},index=[i for i in range(1,5)])\n",
    "compare.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "\n",
    "sns.pointplot(x='Model',y='F1_Score',data=compare)\n",
    "\n",
    "plt.title('Model Vs Score')\n",
    "plt.xlabel('MODEL')\n",
    "plt.ylabel('SCORE')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test With Real Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is a fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Log_Reg.intercept_, Log_Reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = pd.read_csv('../Data/tweetstest.csv')\n",
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = bow_vectorizer.transform(test_text['clean_text']) #use .transform() not .fit_transform()\n",
    "df_bow = pd.DataFrame(bow.todense())\n",
    "df_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_bow = Log_Reg.predict_proba(X)\n",
    "prediction_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"this is a test tweet to predict my gender baby boo\"\n",
    "\n",
    "# Bag-of-Words feature matrix\n",
    "bow = bow_vectorizer.fit_transform('test_text')\n",
    "df_bow = pd.DataFrame(bow.todense())\n",
    "df_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I am so angry\"\n",
    "textBlob = TextBlob(text)\n",
    "print(f\"{textBlob.sentiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ###### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
